{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735db644",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning) # Suppress librosa future warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "# !! IMPORTANT !! These MUST match the parameters used in train_models.py\n",
    "MAX_PAD_LEN = 174\n",
    "N_MFCC = 40\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# Define paths for loading models and scalers (must match saving paths)\n",
    "MODEL_DIR = \"saved_models\"\n",
    "GENDER_MODEL_PATH = os.path.join(MODEL_DIR, 'gender_model.joblib')\n",
    "GENDER_SCALER_PATH = os.path.join(MODEL_DIR, 'gender_scaler.joblib')\n",
    "AGE_MODEL_PATH = os.path.join(MODEL_DIR, 'age_model.joblib')\n",
    "AGE_SCALER_PATH = os.path.join(MODEL_DIR, 'age_scaler.joblib')\n",
    "EMOTION_MODEL_PATH = os.path.join(MODEL_DIR, 'emotion_model.joblib')\n",
    "EMOTION_SCALER_PATH = os.path.join(MODEL_DIR, 'emotion_scaler.joblib')\n",
    "\n",
    "# Define label mappings (MUST match the encoding used during training)\n",
    "# Gender: 0 = Male, 1 = Female (Check encoding used!)\n",
    "gender_map_gui = {0: 'Male', 1: 'Female'}\n",
    "\n",
    "# Age Groups: 0 = Youth, 1 = Adult, 2 = Senior (Check encoding used!)\n",
    "age_map_gui = {0: 'Youth (0-18)', 1: 'Adult (19-60)', 2: 'Senior (61+)'}\n",
    "SENIOR_AGE_LABEL = 'Senior (61+)' # Define the label text that indicates senior\n",
    "\n",
    "# Emotion: (Check encoding used!)\n",
    "emotion_map_gui = {0: 'Neutral', 1: 'Calm', 2: 'Happy', 3: 'Sad', 4: 'Angry', 5: 'Fearful', 6: 'Disgust', 7: 'Surprised'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63109c",
   "metadata": {},
   "source": [
    "## 2. Load Models and Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208dc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Models and Scalers ---\n",
    "try:\n",
    "    print(\"Loading models and scalers...\")\n",
    "    gender_model = joblib.load(GENDER_MODEL_PATH)\n",
    "    gender_scaler = joblib.load(GENDER_SCALER_PATH)\n",
    "    age_model = joblib.load(AGE_MODEL_PATH)\n",
    "    age_scaler = joblib.load(AGE_SCALER_PATH)\n",
    "    emotion_model = joblib.load(EMOTION_MODEL_PATH)\n",
    "    emotion_scaler = joblib.load(EMOTION_SCALER_PATH)\n",
    "    print(\"Models and scalers loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading models/scalers: {e}\")\n",
    "    print(\"Please ensure 'train_models.py' was run successfully and model files exist in the 'saved_models' directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during loading: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c772b",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09dde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Extraction Function (Identical to training script) ---\n",
    "def extract_features(file_path, n_mfcc=N_MFCC, max_pad_len=MAX_PAD_LEN, sr=SAMPLE_RATE):\n",
    "    \"\"\"Extracts MFCC features from an audio file, pads/truncates, and flattens.\"\"\"\n",
    "    try:\n",
    "        # Load audio file (limit duration to prevent excessive memory usage)\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast', sr=sr, duration=10)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "\n",
    "        # Pad or truncate\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        if pad_width > 0:\n",
    "            mfccs_padded = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfccs_padded = mfccs[:, :max_pad_len]\n",
    "\n",
    "        # Flatten\n",
    "        features_flat = mfccs_padded.flatten()\n",
    "        return features_flat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path} for feature extraction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0dddfa",
   "metadata": {},
   "source": [
    "## 4. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc60503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prediction Function ---\n",
    "def predict_audio(file_path):\n",
    "    status_label.config(text=\"Processing audio...\")\n",
    "    root.update_idletasks() # Force GUI update\n",
    "\n",
    "    features = extract_features(file_path)\n",
    "    if features is None:\n",
    "        status_label.config(text=\"Error: Could not extract features from audio.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Reshape for scaler/model (expects 2D array: 1 sample, N features)\n",
    "        features_2d = features.reshape(1, -1)\n",
    "\n",
    "        # 1. Predict Gender\n",
    "        scaled_features_gender = gender_scaler.transform(features_2d)\n",
    "        gender_pred_encoded = gender_model.predict(scaled_features_gender)[0]\n",
    "        gender_pred_label = gender_map_gui.get(gender_pred_encoded, f\"Unknown Gender ({gender_pred_encoded})\")\n",
    "\n",
    "        print(f\"Predicted Gender Code: {gender_pred_encoded}, Label: {gender_pred_label}\") # Debug print\n",
    "\n",
    "        # Check if female\n",
    "        if gender_pred_label == 'Female':\n",
    "            status_label.config(text=\"Upload male voice.\")\n",
    "            return\n",
    "\n",
    "        # 2. Predict Age (since it's Male)\n",
    "        # Assuming age model uses the same features/scaler - If not, adjust feature extraction/scaling here\n",
    "        scaled_features_age = age_scaler.transform(features_2d) # Use age-specific scaler\n",
    "        age_pred_encoded = age_model.predict(scaled_features_age)[0]\n",
    "        age_pred_label = age_map_gui.get(age_pred_encoded, f\"Unknown Age Group ({age_pred_encoded})\")\n",
    "\n",
    "        print(f\"Predicted Age Code: {age_pred_encoded}, Label: {age_pred_label}\") # Debug print\n",
    "\n",
    "        result_text = f\"Gender: {gender_pred_label}\\n\"\n",
    "        result_text += f\"Predicted Age Group: {age_pred_label}\\n\"\n",
    "\n",
    "        # 3. Predict Emotion (Conditionally, if Senior)\n",
    "        is_senior = (age_pred_label == SENIOR_AGE_LABEL)\n",
    "        print(f\"Is Senior: {is_senior}\") # Debug print\n",
    "\n",
    "        if is_senior:\n",
    "            # Assuming emotion model uses the same features/scaler - If not, adjust feature extraction/scaling here\n",
    "            scaled_features_emotion = emotion_scaler.transform(features_2d) # Use emotion-specific scaler\n",
    "            emotion_pred_encoded = emotion_model.predict(scaled_features_emotion)[0]\n",
    "            emotion_pred_label = emotion_map_gui.get(emotion_pred_encoded, f\"Unknown Emotion ({emotion_pred_encoded})\")\n",
    "\n",
    "            print(f\"Predicted Emotion Code: {emotion_pred_encoded}, Label: {emotion_pred_label}\") # Debug print\n",
    "\n",
    "            result_text += \"Status: Senior Citizen\\n\"\n",
    "            result_text += f\"Predicted Emotion: {emotion_pred_label}\"\n",
    "        else:\n",
    "             result_text += \"Status: Not Senior Citizen\" # Explicitly state status\n",
    "\n",
    "        # Display final result\n",
    "        status_label.config(text=result_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        status_label.config(text=f\"An error occurred during prediction: {e}\")\n",
    "        print(f\"Prediction error details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657114a",
   "metadata": {},
   "source": [
    "## 5. GUI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06952e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GUI Setup ---\n",
    "def upload_action():\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Audio File\",\n",
    "            filetypes=((\"Audio Files\", \"*.wav *.mp3\"), (\"All files\", \"*.*\")) # Allow common audio types\n",
    "        )\n",
    "        if file_path: # Proceed only if a file was selected\n",
    "            print(f\"File selected: {file_path}\")\n",
    "            # Basic check if file exists (though dialog usually handles this)\n",
    "            if not os.path.exists(file_path):\n",
    "                 status_label.config(text=\"Error: Selected file not found.\")\n",
    "                 return\n",
    "            predict_audio(file_path)\n",
    "        else:\n",
    "            # status_label.config(text=\"No file selected.\") # Optional: update status if cancelled\n",
    "            print(\"File selection cancelled.\")\n",
    "    except Exception as e:\n",
    "        status_label.config(text=f\"Error during file selection: {e}\")\n",
    "        print(f\"File dialog error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f02af",
   "metadata": {},
   "source": [
    "## 6. Main Application Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Application Window ---\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Age & Emotion Detector (Male Voices)\")\n",
    "    root.geometry(\"450x300\") # Adjusted size for more text\n",
    "\n",
    "    # Use ttk for better widget styling if available\n",
    "    style = ttk.Style()\n",
    "    try:\n",
    "        # Themes: 'clam', 'alt', 'default', 'classic'\n",
    "        style.theme_use('clam')\n",
    "    except tk.TclError:\n",
    "        print(\"ttk 'clam' theme not available, using default.\")\n",
    "\n",
    "    # Frame for content padding and organization\n",
    "    main_frame = ttk.Frame(root, padding=\"20\")\n",
    "    main_frame.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "    # --- Widgets ---\n",
    "    # Title Label\n",
    "    title_label = ttk.Label(main_frame, text=\"Voice Analysis\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "    title_label.pack(pady=(0, 15))\n",
    "\n",
    "    # Upload Button\n",
    "    upload_button = ttk.Button(main_frame, text=\"Upload Audio File (.wav, .mp3)\", command=upload_action, width=30)\n",
    "    upload_button.pack(pady=10)\n",
    "\n",
    "    # Status/Results Label\n",
    "    status_label = ttk.Label(\n",
    "        main_frame,\n",
    "        text=\"Upload an audio file to begin analysis.\",\n",
    "        justify=tk.LEFT,\n",
    "        wraplength=400, # Wrap text within the label width\n",
    "        padding=(10, 10),\n",
    "        relief=tk.SUNKEN, # Add a border effect\n",
    "        borderwidth=1,\n",
    "        anchor='nw' # Anchor text to top-left\n",
    "        )\n",
    "    status_label.pack(pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "\n",
    "    print(\"Starting GUI...\")\n",
    "    root.mainloop()\n",
    "    print(\"GUI closed.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}